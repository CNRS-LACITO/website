<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html> <head>
<meta http-equiv="CONTENT-TYPE" content="text/html; charset=null">
<link rel="StyleSheet" href="DTDDocStyle.css" type="text/css" media="screen">
<title>DTD</title>
</head><body><pre>
&lt;!-- 
(18/06/2005)

The LACITO archive contains a set of documents (narratives, dialogs and word lists).
Each document contains linguistic annotation of an existing audio or video recording.

There are five hierarchical levels defined by the name tags: ARCHIVE, TEXT or WORDLIST, S, W, and M,
and which correspond respectively to: corpus, text or word list, sentence, word, and morpheme. Each
level can contain one or more items from the level just below it. Thus a sentence may be composed of
words, and those words of morphemes, but it is impossible at the sentence level to have a morpheme 
which is not encapsulated in a word. Each level may have its own transcriptions (FORM), translations
(TRANSL) and a time anchor (AUDIO). Translations must specify the target language. On the word and
morpheme levels, the translation corresponds to what are habitually called glosses. The type of
transcription must be specified (phonetic, phonological, orthographical, transliteral...), and may
carry specify the name of the transcriptor as well as the date.

Sentences may contain scenographical indications such as the speaker’s name, in the case of dialogues.

Where necessary, words and morphemes have typological specifications, such as parts of speech, word
classes, etc., the latter being voluntary as each linguist follows his or her own system. Lastly, it
is possible to insert notes almost everywhere.

The time anchoring is established through the insertion, at the desired level, of an AUDIO tag having
two attributes 'start' and 'end', which indicate the temporal values of the beginning and the end (in
milliseconds, starting from the beginning of the recording). This time anchoring base makes it 
possible to express temporal events such as:

1. chronological order: sentences in a narration follow one another;

2. inclusion: words in a sentence are situated between its beginning and its end;

3. overlapping: in a dialogue, several people may speak at the same time.

-->
&lt;!ELEMENT ARCHIVE     (TEXT|WORDLIST)+                       >

&lt;!-- Word list document -->
&lt;!ELEMENT WORDLIST	(HEADER,(NOTE|AUDIO|W)*)	 >



&lt;!-- Narratives or dialogs -->
&lt;!ELEMENT TEXT		(HEADER,(NOTE|FORM|TRANSL|AUDIO|S)*)	 >
&lt;!--
@attr id Unique identifier based on the three-letter code from SIL's Ethnologue (CAPS) followed by
the character ':' followed by the Text's identifier (the text identifier is simply a unique identifier
for all thes texts in a given language).
@attr xml:lang Identification of the language spoken in the whole text.
-->
&lt;!ATTLIST TEXT        	xml:lang        NMTOKEN         #REQUIRED
		      	id              CDATA           #REQUIRED>




&lt;!-- Sentence, phrase (syntactic group, or breath group) -->
&lt;!ELEMENT S		(NOTE|FORM|TRANSL|AUDIO|W)*		 >

&lt;!--
@attr id Unique identifier based on the text identifier followed by the character
's' followed by the sentence's position.
@attr xml:lang Identification of the language spoken in the sentence (in case it is not the 
same as the one spoken in the text).
@attr who The speaker of the sentence (for dialogs the speaker must be specified
for each sentence).
-->
&lt;!ATTLIST S           	id              ID              #REQUIRED
			xml:lang	NMTOKEN	         #IMPLIED
		      	who             CDATA            #IMPLIED>




&lt;!-- Word  -->
&lt;!ELEMENT W		(NOTE|FORM|TRANSL|AUDIO|M)*		 >
&lt;!--
@attr id Unique identifier based on the sentence identifier followed by the character
'w' followed by the word's position.
@attr xml:lang Identification of the language spoken in the word (in case it is not the 
same as the one spoken in the sentence).
-->
&lt;!ATTLIST W           	id              ID               #IMPLIED
			xml:lang	NMTOKEN	         #IMPLIED>






&lt;!-- Morpheme  -->
&lt;!ELEMENT M	 	(NOTE|FORM|TRANSL|AUDIO)*		 >
&lt;!--
@attr id Unique identifier based on the word identifier followed by the character
'm' followed by the morpheme's position.
@attr xml:lang Identification of the language spoken in the morpheme (in case it is not the 
same as the one spoken in the word).
@attr class Morpheme's class (the classes are freely chosen and defined by the linguist annotator).
@attr sclass Morpheme's sub-class (the sub-classes are freely chosen and defined by the linguist annotator).
-->
&lt;!ATTLIST M		id              ID               #IMPLIED
			class	        CDATA            #IMPLIED
			sclass	        CDATA	         #IMPLIED
			xml:lang	NMTOKEN	         #IMPLIED>




&lt;!-- Header (something like a small memento for human readers) -->
&lt;!ELEMENT HEADER	(TITLE*,SOUNDFILE?)	        >
&lt;!-- Title of the document -->
&lt;!ELEMENT TITLE		(#PCDATA)				>
&lt;!-- @attr xml:lang Language identification for the title -->
&lt;!ATTLIST TITLE		xml:lang	NMTOKEN	"en"		>
&lt;!-- Audio or video file annotated in the present document -->
&lt;!ELEMENT SOUNDFILE	EMPTY					>
&lt;!-- @attr href URL of the audio/video document -->
&lt;!ATTLIST SOUNDFILE	href	CDATA	#REQUIRED		>


&lt;!-- Translation. 
For the word and morpheme's levels the translation corresponds to the gloss of the word or morpheme -->
&lt;!ELEMENT TRANSL	(#PCDATA|NOTE)*                    	>
&lt;!-- 
@attr author Author translation 
@attr xml:lang Language identification for the translation
-->
&lt;!ATTLIST TRANSL	xml:lang	NMTOKEN	"en"
			author		CDATA	        #IMPLIED>



&lt;!-- Transcription -->
&lt;!ELEMENT FORM		(#PCDATA|FOREIGN|NOTE)*			>
&lt;!-- 
@attr author Author transcription
@attr kindOf Type of transcription
-->
&lt;!ATTLIST FORM         	author		CDATA	        #IMPLIED
		      	kindOf      (phono|phone|ortho|tranliter)           "phono">




&lt;!-- for loanwords (deprecated) -->
&lt;!ELEMENT FOREIGN	(#PCDATA)				>
&lt;!-- @attr xml:lang Language identification of the loanword -->
&lt;!ATTLIST FOREIGN	xml:lang	NMTOKEN	 #REQUIRED	>

&lt;!-- Time anchoring -->
&lt;!ELEMENT AUDIO       	EMPTY                         		>
&lt;!-- 
@attr start start of the selection (offset: sec.millisec)
@attr end end of the selection (offset: sec.millisec)
-->
&lt;!ATTLIST AUDIO		start	CDATA	#REQUIRED
			end	CDATA	#REQUIRED		>

&lt;!-- Notes, Remarks on a parent element -->
&lt;!ELEMENT NOTE          EMPTY                                   >
&lt;!-- 
@attr message Note's content
@attr author Note's author 
@attr date Note's date of last modification 
@attr kindOf Note's type
@attr xml:lang Notes's language identification 
-->
&lt;!ATTLIST NOTE          xml:lang        NMTOKEN             "en"
                        kindOf          CDATA           #IMPLIED
                        date            CDATA           #IMPLIED
                        author          CDATA           #IMPLIED
                        message         CDATA          #REQUIRED>
</pre></body></html>
